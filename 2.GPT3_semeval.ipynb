{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from helper_functions import openai_prediction\n",
    "\n",
    "# This code requires an OpenAI API key. Before proceeding, you can create one on the OpenAI platform and add it to the relevant field in the creds.json file we have provided.\n",
    "with open(\"creds.json\") as js:\n",
    "    api_key = json.load(js)['OPENAI_API_KEY']\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original = pd.read_csv(\"data/semeval_test.csv\")\n",
    "test_finetuning = pd.read_csv(\"data/openai/semeval_gpt3_test.csv\") # Use this test set to evaluate fine-tuned models\n",
    "\n",
    "# Prompts\n",
    "prompt1=\"Return the TARGET [Trump/Clinton] and STANCE [Favor/Against/None]. Answer: {TARGET, STANCE}\\n\\n\"\n",
    "prompt2=\"This statement may express a STANCE about a TARGET. Return the TARGET [Trump/Clinton] and STANCE [Favor/Against/None]. Answer: {TARGET, STANCE}\\n\\n\"\n",
    "prompt3=\"This statement contains a TARGET and a STANCE. The target is a politician and the stance represents the attitude expressed about them. The target options are Trump or Clinton and stance options are Favor, Against or None. Provide the answer in the following format: {TARGET, STANCE}\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt engineering using GPT3 Davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_zero = copy.deepcopy(test_original)\n",
    "test_zero['prompt1'] = prompt1 + test_zero['prompt'] + \"\\n\"\n",
    "test_zero['prompt2'] = prompt2 + test_zero['prompt'] + \"\\n\"\n",
    "test_zero['prompt3'] = prompt3 + test_zero['prompt'] + \"\\n\"\n",
    "test_zero = test_zero.drop(columns='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = openai_prediction(\n",
    "    model = \"text-davinci-003\",\n",
    "    test_data = test_zero.rename(columns={\"prompt1\":\"prompt\"}),\n",
    "    n_chunks = 17,\n",
    "    result_file_name = \"semeval_davinci_zero_prompt1\")\n",
    "\n",
    "_, _ = openai_prediction(\n",
    "    model = \"text-davinci-003\",\n",
    "    test_data = test_zero.rename(columns={\"prompt2\":\"prompt\"}),\n",
    "    n_chunks = 17,\n",
    "    result_file_name = \"semeval_davinci_zero_prompt2\")\n",
    "\n",
    "_, _ = openai_prediction(\n",
    "    model = \"text-davinci-003\",\n",
    "    test_data = test_zero.rename(columns={\"prompt3\":\"prompt\"}),\n",
    "    n_chunks = 17,\n",
    "    result_file_name = \"semeval_davinci_zero_prompt3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zero-shot with prompt 3\n",
    "_, _ = openai_prediction(\n",
    "    model = \"text-davinci-003\", # \"text-ada-001\"\n",
    "    test_data = test_zero.rename(columns={\"prompt3\":\"prompt\"}),\n",
    "    n_chunks = 17,\n",
    "    result_file_name = \"semeval_davinci_zero_prompt3\") # \"ada\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot prediction with 100 Clinton and 100 Trump tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_100 = pd.read_csv(\"data/semeval_train_100.csv\")\n",
    "\n",
    "for i, eg in enumerate(train_100.iterrows()):\n",
    "    test_few = copy.deepcopy(test_original)\n",
    "    test_few['prompt'] = prompt3 + \"###\\n\" + eg[1].iloc[0] + \"\\n###\\n\" + test_few['prompt'] + \"\\n\"\n",
    "    \n",
    "    _, _ = openai_prediction(\n",
    "    model = \"text-davinci-003\", # \"text-ada-001\"\n",
    "    test_data = test_few,\n",
    "    n_chunks = 17,\n",
    "    result_file_name = f\"semeval_davinci_one_eg_{i}\") # ada"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_10 = openai.FineTune.create(\n",
    "    training_file=\"YOUR_FILE_ID\",\n",
    "    model=\"davinci\" # \"ada\"\n",
    ")\n",
    "finetune_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_100 = openai.FineTune.create(\n",
    "    training_file=\"YOUR_FILE_ID\",\n",
    "    model=\"davinci\" # \"ada\"\n",
    ")\n",
    "finetune_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_all = openai.FineTune.create(\n",
    "    training_file=\"YOUR_FILE_ID\",\n",
    "    model=\"davinci\" # \"ada\"\n",
    ")\n",
    "finetune_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = openai_prediction(\n",
    "    model = \"MODEL10\",\n",
    "    test_data = test_finetuning,\n",
    "    n_chunks = 20,\n",
    "    result_file_name = \"semeval_davinci_10\") # \"ada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = openai_prediction(\n",
    "    model = \"MODEL100\",\n",
    "    test_data = test_finetuning,\n",
    "    n_chunks = 20,\n",
    "    result_file_name = \"semeval_davinci_100\") # \"ada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = openai_prediction(\n",
    "    model = \"MODEL_all\",\n",
    "    test_data = test_finetuning,\n",
    "    n_chunks = 20,\n",
    "    result_file_name = \"semeval_davinci_all\") # \"ada\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
