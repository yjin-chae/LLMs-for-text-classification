{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "mapping = {\"S\":\"Favor\", \"O\":\"Against\", \"N\":\"None\"}\n",
    "\n",
    "data = pd.read_csv(\"data/original/facebook_comments.csv\", encoding='unicode_escape', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data for Facebook Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[:, [\"page\", \"comment_message\", \"Clinton\", \"Trump\"]]\n",
    "data = data.rename(columns={\"comment_message\":\"prompt\"})\n",
    "data['Clinton'] = data['Clinton'].replace(mapping, regex=True)\n",
    "data['Trump'] = data['Trump'].replace(mapping, regex=True)\n",
    "\n",
    "data['completion'] = data['Trump'].str.strip() + \", \" + data['Clinton'].str.strip()\n",
    "trump = data.loc[data['page']==\"Trump\"]\n",
    "clinton = data.loc[data['page']==\"Clinton\"]\n",
    "\n",
    "clinton_train, clinton_test = train_test_split(clinton, test_size=200, shuffle=True)\n",
    "trump_train, trump_test = train_test_split(trump, test_size=200, shuffle=True)\n",
    "\n",
    "train = pd.concat([clinton_train, trump_train], axis=0).sample(frac=1, replace=False).reset_index(drop=True)\n",
    "test = pd.concat([clinton_test, trump_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "train.loc[:,[\"prompt\", \"completion\"]].to_csv(\"data/fb_train.csv\", index=False)\n",
    "test.loc[:,[\"prompt\", \"completion\"]].to_csv(\"data/fb_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot examples generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exemplar = train.sample(100, replace=False)\n",
    "train_exemplar['prompt'] = \"Example:\\n\" + train_exemplar['prompt'] + \"\\nTrump: \" + train_exemplar[\"Trump\"] + \", \" + \"Clinton: \" + train_exemplar[\"Clinton\"] + \"\\n\"\n",
    "train_exemplar.loc[:,\"prompt\"].to_csv(\"data/fb_train_exemplar.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning data for GPT3 Ada, Davinci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "if not os.path.exists(\"data/openai\"):\n",
    "    os.makedirs(\"data/openai\")\n",
    "\n",
    "def formatter(df: pd.DataFrame):\n",
    "    output = df.copy()\n",
    "    output['prompt'] = df['prompt'] + \"\\nStance:\"\n",
    "    output['completion'] = \" \" + df['completion'] + \"\\n\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat according to GPT3 fine-tuning requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_openai = formatter(train)\n",
    "test_openai = formatter(test)\n",
    "test_openai.loc[:,[\"prompt\", \"completion\"]].to_csv(\"data/openai/fb_gpt3_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_gpt3 = train_openai.loc[:,['prompt', 'completion']]\n",
    "fb_gpt3_10 = fb_gpt3[:10]\n",
    "fb_gpt3_100 = fb_gpt3[:100]\n",
    "fb_gpt3_1000 = fb_gpt3[:1000]\n",
    "fb_gpt3_all = fb_gpt3.copy()\n",
    "\n",
    "fb_gpt3_10.to_json(\"data/openai/fb_gpt3_10.jsonl\", orient='records', lines=True)\n",
    "fb_gpt3_100.to_json(\"data/openai/fb_gpt3_100.jsonl\", orient='records', lines=True)\n",
    "fb_gpt3_1000.to_json(\"data/openai/fb_gpt3_1000.jsonl\", orient='records', lines=True)\n",
    "fb_gpt3_all.to_json(\"data/openai/fb_gpt3_all.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data for fine-tuning\n",
    "openai.File.create(file=open(\"data/openai/fb_gpt3_10.jsonl\"), user_provided_filename=\"fb_gpt3_10\", purpose=\"fine-tune\") \n",
    "openai.File.create(file=open(\"data/openai/fb_gpt3_100.jsonl\"), user_provided_filename=\"fb_gpt3_100\", purpose=\"fine-tune\") \n",
    "openai.File.create(file=open(\"data/openai/fb_gpt3_1000.jsonl\"), user_provided_filename=\"fb_gpt3_1000\", purpose=\"fine-tune\") \n",
    "openai.File.create(file=open(\"data/openai/fb_gpt3_all.jsonl\"), user_provided_filename=\"fb_gpt3_all\", purpose=\"fine-tune\") \n",
    "\n",
    "openai.File.list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
